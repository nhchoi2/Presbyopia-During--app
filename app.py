import streamlit as st
import numpy as np
import tensorflow as tf
from PIL import Image

# utils ëª¨ë“ˆ ì„í¬íŠ¸
from utils.face_detect import detect_and_crop_face
from utils.feedback import get_feedback
from utils.share_link import get_share_links
from utils.ai_chatbot import get_ai_response

def load_model(model_path):
    """
    keras_model.h5 íŒŒì¼ì„ ë¡œë“œí•´ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    model = tf.keras.models.load_model(model_path)
    return model

def load_labels(label_path):
    """
    labels.txt íŒŒì¼ì„ ì½ì–´ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    with open(label_path, "r", encoding="utf-8") as f:
        labels = [line.strip() for line in f.readlines()]
    return labels

def main():
    st.title("ë™ì•ˆ vs ë…¸ì•ˆ íŒë³„ê¸° ğŸ‘¶ğŸ§“")

    # ëª¨ë¸ ë° ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°
    model_path = "model/keras_model.h5"
    label_path = "model/labels.txt"

    model = load_model(model_path)
    labels = load_labels(label_path)

    st.write("Google Teachable Machineìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    st.write("ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´, ëª¨ë¸ì´ ë™ì•ˆì¸ì§€ ë…¸ì•ˆì¸ì§€ íŒë³„í•©ë‹ˆë‹¤.")

    # ì‚¬ì§„ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None:
        # PIL ì´ë¯¸ì§€ ì—´ê¸°
        image = Image.open(uploaded_file)

        # ì–¼êµ´ ìë™ í¬ë¡­(ì˜µì…˜)
        cropped_image = detect_and_crop_face(image)

        # ì´ë¯¸ì§€ í‘œì‹œ
        st.image(cropped_image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€(ìë™ ì–¼êµ´ í¬ë¡­ ì ìš©)", use_column_width=True)

        # ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ ì „ì²˜ë¦¬
        # Google Teachable Machine ê¸°ë³¸ ëª¨ë¸ ì…ë ¥ í¬ê¸°(224x224) ë“±ìœ¼ë¡œ ê°€ì •
        processed_img = cropped_image.resize((224, 224))
        img_array = np.array(processed_img) / 255.0  # ìŠ¤ì¼€ì¼ë§
        img_array = np.expand_dims(img_array, axis=0)  # (1, 224, 224, 3)

        # ì˜ˆì¸¡
        predictions = model.predict(img_array)
        # ì˜ˆ: [ [0.2, 0.8] ] í˜•íƒœë¼ê³  ê°€ì •
        pred_index = np.argmax(predictions[0])
        confidence = predictions[0][pred_index]

        result_label = labels[pred_index]

        # ê²°ê³¼ ì¶œë ¥
        st.markdown(f"**íŒì • ê²°ê³¼:** {result_label}")
        st.markdown(f"**í™•ë¥ :** {confidence * 100:.2f}%")

        # í”¼ë“œë°± ë©”ì‹œì§€
        feedback_msg = get_feedback(result_label)
        st.info(feedback_msg)

        # SNS ê³µìœ  ë§í¬
        share_links = get_share_links(result_label)
        st.markdown("**ê²°ê³¼ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”!**")
        st.markdown(f"[íŠ¸ìœ„í„°ë¡œ ê³µìœ í•˜ê¸°]({share_links['twitter']})")
        st.markdown(f"[í˜ì´ìŠ¤ë¶ìœ¼ë¡œ ê³µìœ í•˜ê¸°]({share_links['facebook']})")

    st.markdown("---")
    st.header("AI ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°")
    user_input = st.text_input("ì±—ë´‡ì—ê²Œ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”.")
    if user_input:
        chatbot_answer = get_ai_response(user_input)
        st.write(f"**AI ë‹µë³€:** {chatbot_answer}")

if __name__ == "__main__":
    main()
